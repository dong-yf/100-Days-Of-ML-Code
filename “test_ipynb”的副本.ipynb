{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "“test.ipynb”的副本",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dong-yf/100-Days-Of-ML-Code/blob/master/%E2%80%9Ctest_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJqhNzi_Be0U",
        "outputId": "ba220f05-918b-424e-d6f2-a8c9d8d3b6bc"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYbzWXup_Iim"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oClxEKsRGeAW"
      },
      "source": [
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUWTahU8_IjC"
      },
      "source": [
        "# Training parameters\n",
        "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
        "epochs = 100\n",
        "data_augmentation = True\n",
        "num_classes = 20\n",
        "subtract_pixel_mean = True\n",
        "n = 3\n",
        "depth = n * 6 + 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgGEtkp7H5zo"
      },
      "source": [
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\r\n",
        "model_name = 'keras_model.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_-GpJlX_IjF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1baeeb42-1079-430f-b3de-c984e5c0a7f6"
      },
      "source": [
        "split_rate = 0.2\n",
        "def split_validation(train, split_rate):\n",
        "    validation_index = int(len(train) * split_rate);\n",
        "    validation = train[-validation_index:];\n",
        "    train = train[:-validation_index];\n",
        "    return train, validation\n",
        "batch_size = 32 \n",
        "num_classes = 20\n",
        "epochs = 100\n",
        "data_augmentation = True\n",
        "#读入训练集和测试集\n",
        "data = np.load(\"q1_data/train.npy\")\n",
        "x_train = data.reshape(data.shape[0], 3, 32, 32).transpose(0, 2, 3, 1)\n",
        "df = pd.read_csv('q1_data/train1.csv')\n",
        "y_train = df['coarse_label'].values\n",
        "data = np.load(\"q1_data/test.npy\")\n",
        "x_test = data.reshape(data.shape[0], 3, 32, 32).transpose(0, 2, 3, 1)\n",
        "#在训练集中分割验证集\n",
        "x_train, x_validation = split_validation(x_train, split_rate)\n",
        "y_train, y_validation = split_validation(y_train, split_rate)\n",
        "x_train = x_train.astype('float32')\n",
        "x_validation = x_validation.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_validation /= 255\n",
        "x_test /= 255\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_validation = keras.utils.to_categorical(y_validation, num_classes)\n",
        "print(x_validation.shape)\n",
        "print(y_validation.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 32, 32, 3)\n",
            "(10000, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh_Nnmu4_IjL"
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    # Learning Rate Schedule\n",
        "    lr = 0.1\n",
        "    if epoch > 100:\n",
        "        lr *= 0.1\n",
        "    if epoch > 200:\n",
        "        lr *= 0.1\n",
        "    if epoch > 300:\n",
        "        lr *= 0.1\n",
        "    if epoch > 400:\n",
        "        lr *= 0.1\n",
        "    \n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pH80yx_FADw"
      },
      "source": [
        "def resnet_layer(inputs,\r\n",
        "                 num_filters=16,\r\n",
        "                 kernel_size=3,\r\n",
        "                 strides=1,\r\n",
        "                 activation='relu',\r\n",
        "                 batch_normalization=True,\r\n",
        "                 conv_first=True):\r\n",
        "    # ResNet block\r\n",
        "    conv = Conv2D(num_filters,\r\n",
        "                  kernel_size=kernel_size,\r\n",
        "                  strides=strides,\r\n",
        "                  padding='same',\r\n",
        "                  kernel_initializer='he_normal',\r\n",
        "                  kernel_regularizer=l2(1e-4))\r\n",
        "\r\n",
        "    x = inputs\r\n",
        "    if conv_first:\r\n",
        "        x = conv(x)\r\n",
        "        if batch_normalization:\r\n",
        "            x = BatchNormalization()(x)\r\n",
        "        if activation is not None:\r\n",
        "            x = Activation(activation)(x)\r\n",
        "    else:\r\n",
        "        if batch_normalization:\r\n",
        "            x = BatchNormalization()(x)\r\n",
        "        if activation is not None:\r\n",
        "            x = Activation(activation)(x)\r\n",
        "        x = conv(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "def resnet(input_shape, depth, num_classes=20):\r\n",
        "    # Start model definition.\r\n",
        "    num_filters = 16\r\n",
        "    num_res_blocks = int((depth - 2) / 6)\r\n",
        "\r\n",
        "    inputs = Input(shape=input_shape)\r\n",
        "    x = resnet_layer(inputs=inputs)\r\n",
        "    # Instantiate the stack of residual units\r\n",
        "    for stack in range(3):\r\n",
        "        for res_block in range(num_res_blocks):\r\n",
        "            strides = 1\r\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n",
        "                strides = 2  # downsample\r\n",
        "            y = resnet_layer(inputs=x,\r\n",
        "                             num_filters=num_filters,\r\n",
        "                             strides=strides)\r\n",
        "            y = resnet_layer(inputs=y,\r\n",
        "                             num_filters=num_filters,\r\n",
        "                             activation=None)\r\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n",
        "                # linear projection residual shortcut connection to match\r\n",
        "                # changed dims\r\n",
        "                x = resnet_layer(inputs=x,\r\n",
        "                                 num_filters=num_filters,\r\n",
        "                                 kernel_size=1,\r\n",
        "                                 strides=strides,\r\n",
        "                                 activation=None,\r\n",
        "                                 batch_normalization=False)\r\n",
        "            x = keras.layers.add([x, y])\r\n",
        "            x = Activation('relu')(x)\r\n",
        "        num_filters *= 2\r\n",
        "\r\n",
        "    # Add classifier on top.\r\n",
        "    x = AveragePooling2D(pool_size=8)(x)\r\n",
        "    y = Flatten()(x)\r\n",
        "    outputs = Dense(num_classes,\r\n",
        "                    activation='softmax',\r\n",
        "                    kernel_initializer='he_normal')(y)\r\n",
        "\r\n",
        "    # Instantiate model.\r\n",
        "    model = Model(inputs=inputs, outputs=outputs)\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMj223KOjQvE"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32,32,3)))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(256, activation='relu'))\r\n",
        "model.add(Dense(128, activation='relu'))\r\n",
        "model.add(Dense(20, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CGdQJbJKKgU",
        "outputId": "2b82c14c-806e-4229-d364-7b9374bec53d"
      },
      "source": [
        "#model = resnet(input_shape=x_train.shape[1:], depth=depth)\r\n",
        "sgd = keras.optimizers.SGD(lr=lr_schedule(0), decay=1e-4, momentum=0.9)\r\n",
        "model.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=sgd,\r\n",
        "              metrics=['accuracy'])\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.1\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 20)                2580      \n",
            "=================================================================\n",
            "Total params: 260,052\n",
            "Trainable params: 260,052\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NO4qt3ZH3uX",
        "outputId": "791fb664-953d-47ad-ac7e-21deb10d0420"
      },
      "source": [
        "if not os.path.isdir(save_dir):\r\n",
        "    os.makedirs(save_dir)\r\n",
        "model_path = os.path.join(save_dir, model_name)\r\n",
        "model.save(model_path)\r\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved trained model at /content/gdrive/My Drive/Colab Notebooks/saved_models/keras_model.h5 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNvzSTsVNixD"
      },
      "source": [
        "filepath = 'saved_models/ResNet_model.h5'\r\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\r\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\r\n",
        "                             monitor='val_accuracy',\r\n",
        "                             verbose=1,\r\n",
        "                             save_best_only=True)\r\n",
        "\r\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\r\n",
        "\r\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\r\n",
        "                               cooldown=0,\r\n",
        "                               patience=5,\r\n",
        "                               min_lr=0.5e-6)\r\n",
        "\r\n",
        "tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph', \r\n",
        "                                         histogram_freq=0, \r\n",
        "                                         write_graph=True, \r\n",
        "                                         write_images=True)\r\n",
        "callbacks = [checkpoint, tbCallBack, lr_scheduler, lr_reducer]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puEcy4MIObpv"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\r\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\r\n",
        "    samplewise_center=False,  # set each sample mean to 0\r\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\r\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\r\n",
        "    zca_whitening=False,  # apply ZCA whitening\r\n",
        "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\r\n",
        "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\r\n",
        "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\r\n",
        "    horizontal_flip=True,  # randomly flip images\r\n",
        "    vertical_flip=False)  # randomly flip images\r\n",
        "train_datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8bdZgP6Olxz",
        "outputId": "0fbb3a88-1139-40f3-ae6e-20507f81cb5e"
      },
      "source": [
        "# Fit the model on the batches generated by datagen.flow().\r\n",
        "model.fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size),\r\n",
        "                    validation_data=(x_validation, y_validation),\r\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,\r\n",
        "                    epochs=epochs, verbose=1, workers=4,\r\n",
        "                    callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.1\n",
            "Epoch 1/100\n",
            "   2/1250 [..............................] - ETA: 1:00 - loss: 2.9872 - accuracy: 0.0312  WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0140s vs `on_train_batch_end` time: 0.0899s). Check your callbacks.\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 2.7965 - accuracy: 0.0617\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.00000, saving model to saved_models/ResNet_model.h5\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 2.7964 - accuracy: 0.0616 - val_loss: 7.0060 - val_accuracy: 0.0000e+00\n",
            "Learning rate:  0.1\n",
            "Epoch 2/100\n",
            "  86/1250 [=>............................] - ETA: 21s - loss: 2.7832 - accuracy: 0.0705"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}